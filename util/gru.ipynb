{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting implicit ratings from movielens 1M dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "import numpy as np\n",
    "from absl import flags\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x7f601434dcc0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string(\"file_path\", \"ml-1m/ratings.dat\", \"file path.\")\n",
    "flags.DEFINE_string(\"train_path\", \"ml-1m/ml_seq_train.txt\", \"train path. If set to None, the program will split the dataset.\")\n",
    "flags.DEFINE_string(\"val_path\", \"ml-1m/ml_seq_val.txt\", \"val path.\")\n",
    "flags.DEFINE_string(\"test_path\", \"ml-1m/ml_seq_test.txt\", \"test path.\")\n",
    "flags.DEFINE_string(\"meta_path\", \"ml-1m/ml_seq_meta.txt\", \"meta path.\")\n",
    "flags.DEFINE_integer(\"embed_dim\", 64, \"The size of embedding dimension.\")\n",
    "flags.DEFINE_float(\"embed_reg\", 0.0, \"The value of embedding regularization.\")\n",
    "flags.DEFINE_integer(\"gru_layers\", 2, \"The number of GRU Layers.\")\n",
    "flags.DEFINE_integer(\"gru_unit\", 128, \"The unit of GRU Layer.\")\n",
    "flags.DEFINE_string(\"gru_activation\", \"tanh\", \"Activation Name.\")\n",
    "flags.DEFINE_float(\"dnn_dropout\", 0., \"Float between 0 and 1. Dropout of user and item MLP layer.\")\n",
    "flags.DEFINE_boolean(\"use_l2norm\", False, \"Whether user embedding, item embedding should be normalized or not.\")\n",
    "flags.DEFINE_string(\"loss_name\", \"bpr_loss\", \"Loss Name.\")\n",
    "flags.DEFINE_float(\"gamma\", 0.5, \"If hinge_loss is selected as the loss function, you can specify the margin.\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.001, \"Learning rate.\")\n",
    "flags.DEFINE_integer(\"neg_num\", 4, \"The number of negative sample for each positive sample.\")\n",
    "flags.DEFINE_integer(\"seq_len\", 16, \"The length of user's behavior sequence.\")\n",
    "flags.DEFINE_integer(\"epochs\", 10, \"train steps.\")\n",
    "flags.DEFINE_integer(\"batch_size\", 128, \"Batch Size.\")\n",
    "flags.DEFINE_integer(\"test_neg_num\", 4, \"The number of test negative samples.\")\n",
    "flags.DEFINE_integer(\"k\", 10, \"recall k items at test stage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-1m.zip\", \"movielens.zip\")\n",
    "ZipFile(\"movielens.zip\", \"r\").extractall(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence recommendation\n",
    "def split_seq_data(file_path):\n",
    "    \"\"\"split movielens for sequence recommendation\n",
    "    Args:\n",
    "        :param file_path: A string. The file path of 'ratings.dat'.\n",
    "    :return: train_path, val_path, test_path, meta_path\n",
    "    \"\"\"\n",
    "    dst_path = os.path.dirname(file_path)\n",
    "    train_path = os.path.join(dst_path, \"ml_seq_train.txt\")\n",
    "    val_path = os.path.join(dst_path, \"ml_seq_val.txt\")\n",
    "    test_path = os.path.join(dst_path, \"ml_seq_test.txt\")\n",
    "    meta_path = os.path.join(dst_path, \"ml_seq_meta.txt\")\n",
    "    users, items = set(), set()\n",
    "    history = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in tqdm(lines):\n",
    "            user, item, score, timestamp = line.strip().split(\"::\")\n",
    "            users.add(int(user))\n",
    "            items.add(int(item))\n",
    "            history.setdefault(int(user), [])\n",
    "            history[int(user)].append([item, timestamp])\n",
    "        random.shuffle(list(users))\n",
    "    with open(train_path, 'w') as f1, open(val_path, 'w') as f2, open(test_path, 'w') as f3:\n",
    "        for user, hist in history.items():\n",
    "            hist_u = history[int(user)]\n",
    "            hist_u.sort(key=lambda x: x[1])\n",
    "            hist = [x[0] for x in hist_u]\n",
    "            time = [x[1] for x in hist_u]\n",
    "            f1.write(str(user) + \"\\t\" + ' '.join(hist[:-2]) + \"\\t\" + ' '.join(time[:-2]) + '\\n')\n",
    "            f2.write(str(user) + \"\\t\" + ' '.join(hist[:-2]) + \"\\t\" + ' '.join(time[:-2]) + \"\\t\" + hist[-2] + '\\n')\n",
    "            f3.write(str(user) + \"\\t\" + ' '.join(hist[:-1]) + \"\\t\" + ' '.join(time[:-1]) + \"\\t\" + hist[-1] + '\\n')\n",
    "    with open(meta_path, 'w') as f:\n",
    "        f.write(str(max(users)) + '\\t' + str(max(items)))\n",
    "    return train_path, val_path, test_path, meta_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000209/1000209 [00:03<00:00, 282181.77it/s]\n"
     ]
    }
   ],
   "source": [
    "train_path, val_path, test_path, meta_path = split_seq_data(file_path=\"../data/ml-1m/ratings.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_seq_data(file_path, mode, seq_len, neg_num, max_item_num, contain_user=False, contain_time=False):\n",
    "    \"\"\"load sequence movielens dataset.\n",
    "    Args:\n",
    "        :param file_path: A string. The file path.\n",
    "        :param mode: A string. \"train\", \"val\" or \"test\".\n",
    "        :param seq_len: A scalar(int). The length of sequence.\n",
    "        :param neg_num: A scalar(int). The negative num of one sample.\n",
    "        :param max_item_num: A scalar(int). The max index of item.\n",
    "        :param contain_user: A boolean. Whether including user'id input or not.\n",
    "        :param contain_time: A boolean. Whether including time sequence input or not.\n",
    "    :return: A dict. data.\n",
    "    \"\"\"\n",
    "    users, click_seqs, time_seqs, pos_items, neg_items = [], [], [], [], []\n",
    "    with open(file_path) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in tqdm(lines):\n",
    "            if mode == \"train\":\n",
    "                user, click_seq, time_seq = line.split('\\t')\n",
    "                click_seq = click_seq.split(' ')\n",
    "                click_seq = [int(x) for x in click_seq]\n",
    "                time_seq = time_seq.split(' ')\n",
    "                for i in range(len(click_seq)-1):\n",
    "                    if i + 1 >= seq_len:\n",
    "                        tmp = click_seq[i+1-seq_len:i+1]\n",
    "                        tmp2 = time_seq[i + 1 - seq_len:i + 1]\n",
    "                    else:\n",
    "                        tmp = [0] * (seq_len-i-1) + click_seq[:i+1]\n",
    "                        tmp2 = [0] * (seq_len - i - 1) + time_seq[:i + 1]\n",
    "                    # gen_neg = _gen_negative_samples(neg_num, click_seq, max_item_num)\n",
    "                    # neg_item = [neg_item for neg_item in gen_neg]\n",
    "                    neg_item = [random.randint(1, max_item_num) for _ in range(neg_num)]\n",
    "                    users.append(int(user))\n",
    "                    click_seqs.append(tmp)\n",
    "                    time_seqs.append(tmp2)\n",
    "                    pos_items.append(click_seq[i + 1])\n",
    "                    neg_items.append(neg_item)\n",
    "            else:  # \"val\", \"test\"\n",
    "                user, click_seq, time_seq, pos_item = line.split('\\t')\n",
    "                click_seq = click_seq.split(' ')\n",
    "                click_seq = [int(x) for x in click_seq]\n",
    "                time_seq = time_seq.split(' ')\n",
    "                if len(click_seq) >= seq_len:\n",
    "                    tmp = click_seq[len(click_seq) - seq_len:]\n",
    "                    tmp2 = time_seq[len(time_seq) - seq_len:]\n",
    "                else:\n",
    "                    tmp = [0] * (seq_len - len(click_seq)) + click_seq[:]\n",
    "                    tmp2 = [0] * (seq_len - len(time_seq)) + time_seq[:]\n",
    "                # Currently getting negative samples at random.\n",
    "                # Retrieve negative samples by checking ratings, if < \n",
    "                neg_item = [random.randint(1, max_item_num) for _ in range(neg_num)]\n",
    "                users.append(int(user))\n",
    "                click_seqs.append(tmp)\n",
    "                time_seqs.append(tmp2)\n",
    "                pos_items.append(int(pos_item))\n",
    "                neg_items.append(neg_item)\n",
    "    data = list(zip(users, click_seqs, time_seqs, pos_items, neg_items))\n",
    "    random.shuffle(data)\n",
    "    users, click_seqs, time_seqs, pos_items, neg_items = zip(*data)\n",
    "    data = {'click_seq': np.array(click_seqs), 'pos_item': np.array(pos_items), 'neg_item': np.array(neg_items)}\n",
    "    if contain_user:\n",
    "        data['user'] = np.array(users)\n",
    "    if contain_time:\n",
    "        data['time_seq'] = np.array(time_seqs)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(meta_path) as f:\n",
    "        _, max_item_num = [int(x) for x in f.readline().strip('\\n').split('\\t')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../data/ml_seq_train.txt\"\n",
    "val_path = \"../data/ml_seq_val.txt\"\n",
    "test_path = \"../data/ml_seq_test.txt\"\n",
    "meta_path = \"../data/ml_seq_meta.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:08<00:00, 691.61it/s] \n",
      "100%|██████████| 6040/6040 [00:00<00:00, 22027.87it/s]\n",
      "100%|██████████| 6040/6040 [00:00<00:00, 20644.35it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = load_seq_data(train_path, \"train\", seq_len=16, neg_num=4, max_item_num=max_item_num)\n",
    "val_data = load_seq_data(val_path, \"val\", seq_len=16, neg_num=4, max_item_num=max_item_num)\n",
    "test_data = load_seq_data(test_path, \"test\", seq_len=16, neg_num=4, max_item_num=max_item_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 512  903 1479 ... 1274 2268  923]\n"
     ]
    }
   ],
   "source": [
    "print(train_data['pos_item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'item_num': max_item_num + 1,\n",
    "    'embed_dim': 64,\n",
    "    'gru_layers': 2,\n",
    "    'gru_unit': 128,\n",
    "    'gru_activation': 'tanh',\n",
    "    'dnn_dropout': 0,\n",
    "    'use_l2norm': False,\n",
    "    'loss_name': 'bpr_loss',\n",
    "    'gamma': 0.5,\n",
    "    'embed_reg': 0.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataset(data.Dataset):\n",
    "    \"\"\"Movie dataset.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, data,test=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with user,past,future.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['click_seq'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(self.data)\n",
    "        seq_clicks = self.data['click_seq'][idx]\n",
    "        pos_item = self.data['pos_item'][idx]\n",
    "        neg_item = self.data['neg_item'][idx]\n",
    "        \n",
    "        seq_clicks = torch.LongTensor(seq_clicks)\n",
    "        # pos_item = torch.LongTensor(pos_item)\n",
    "        neg_item = torch.LongTensor(neg_item)\n",
    "        \n",
    "        return seq_clicks, pos_item, neg_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 339, 2012, 2961, 2052, 1911, 1690,  366,  426,  879,  332, 1999, 2107,\n",
       "         1324, 2995, 2315,  196]),\n",
       " 512,\n",
       " tensor([2580, 2894, 1414, 2024]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = MovieDataset(train_data)\n",
    "train_ds.__getitem__(0)\n",
    "# print(train_ds.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(pos_scores, neg_scores, loss_name, gamma=None):\n",
    "    \"\"\"Get loss scores.\n",
    "    Args:\n",
    "        :param pos_scores: A tensor with shape of [batch_size, 1].\n",
    "        :param neg_scores: A tensor with shape of [batch_size, neg_num].\n",
    "        :param loss_name: A string such as 'bpr_loss', 'hing_loss' and etc.\n",
    "        :param gamma: A scalar(int). If loss_name == 'hinge_loss', the gamma must be valid.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pos_scores = torch.tile(pos_scores, [1, neg_scores.shape[1]])\n",
    "    if loss_name == 'bpr_loss':\n",
    "        loss = bpr_loss(pos_scores, neg_scores)\n",
    "    return loss\n",
    "\n",
    "def bpr_loss(pos_scores, neg_scores):\n",
    "    \"\"\"bpr loss.\n",
    "    Args:\n",
    "        :param pos_scores: A tensor with shape of [batch_size, 1].\n",
    "        :param neg_scores: A tensor with shape of [batch_size, neg_num].\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    loss = torch.mean(-torch.log(torch.special.expit(pos_scores - neg_scores)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU4Rec(pl.LightningModule):\n",
    "    def __init__(self, item_num, embed_dim, gru_layers=1, gru_unit=64, gru_activation='tanh',\n",
    "                 dnn_dropout=0., use_l2norm=False, loss_name='bpr_loss', gamma=0.5, embed_reg=0., seed=None):\n",
    "        \"\"\"GRU4Rec, Sequential Recommendation Model.\n",
    "        Args:\n",
    "            :param item_num: An integer type. The largest item index + 1.\n",
    "            :param embed_dim: An integer type. Embedding dimension of item vector.\n",
    "            :param gru_layers: An integer type. The number of GRU Layers.\n",
    "            :param gru_unit:An integer type. The unit of GRU Layer.\n",
    "            :param gru_activation: A string. The name of activation function. Default 'tanh'.\n",
    "            :param dnn_dropout: Float between 0 and 1. Dropout of user and item MLP layer.\n",
    "            :param use_l2norm: A boolean. Whether user embedding, item embedding should be normalized or not.\n",
    "            :param loss_name: A string. You can specify the current point-loss function 'binary_cross_entropy_loss' or\n",
    "            pair-loss function as 'bpr_loss'、'hinge_loss'.\n",
    "            :param gamma: A float type. If hinge_loss is selected as the loss function, you can specify the margin.\n",
    "            :param embed_reg: A float type. The regularizer of embedding.\n",
    "            :param seed: A Python integer to use as random seed.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        super(GRU4Rec, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self._device = torch.device('cpu')\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=item_num,\n",
    "                                           embedding_dim=embed_dim,\n",
    "                                           norm_type=2 if use_l2norm else 0, max_norm=0.0)\n",
    "        self.dropout = nn.Dropout(dnn_dropout)\n",
    "        # self.gru_layers = [\n",
    "        #     nn.GRU(input_size=gru_unit, )\n",
    "        #     if i < gru_layers - 1 else\n",
    "        #     GRU(units=gru_unit, activation=gru_activation, return_sequences=False)\n",
    "        #     for i in range(gru_layers)\n",
    "        # ]\n",
    "        self.gru_layers = nn.GRU(input_size=embed_dim, hidden_size=gru_unit,\n",
    "                                 num_layers=gru_layers, dropout=dnn_dropout, batch_first=True)\n",
    "        self.dense = nn.Linear(embed_dim, embed_dim)\n",
    "        # norm\n",
    "        self.use_l2norm = use_l2norm\n",
    "        # loss name\n",
    "        self.loss_name = loss_name\n",
    "        self.gamma = gamma\n",
    "        self.hidden_size = gru_unit\n",
    "        self.activation = self.final_activation(\"tanh\")\n",
    "        self.hidden = self.init_hidden()\n",
    "        # seed\n",
    "        # tf.random.set_seed(seed)\n",
    "\n",
    "    def create_final_activation(self, final_act):\n",
    "        if final_act == 'tanh':\n",
    "            self.final_activation = nn.Tanh()\n",
    "        elif final_act == 'relu':\n",
    "            self.final_activation = nn.ReLU()\n",
    "        elif final_act == 'softmax':\n",
    "            self.final_activation = nn.Softmax()\n",
    "        elif final_act == 'softmax_logit':\n",
    "            self.final_activation = nn.LogSoftmax()\n",
    "        elif final_act.startswith('elu-'):\n",
    "            self.final_activation = nn.ELU(\n",
    "                alpha=float(final_act.split('-')[1]))\n",
    "        elif final_act.startswith('leaky-'):\n",
    "            self.final_activation = nn.LeakyReLU(\n",
    "                negative_slope=float(final_act.split('-')[1]))\n",
    "\n",
    "    def embed_inputs(self, inputs):\n",
    "        \"\"\"Embedding inputs.\n",
    "        Args:\n",
    "            :param inputs: A list of tensors. The first tensor is seq_clicks tensor, the second tensor is pos_items tensor, the third tensor is neg_items tensor.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        seq_clicks, pos_item, neg_item = inputs\n",
    "        seq_embed = self.item_embedding(seq_clicks)\n",
    "        print(f\"Seq Embedding Shape: {seq_embed.size()}\")\n",
    "        pos_info = self.item_embedding(pos_item)\n",
    "        print(f\"Pos Embedding Shape: {pos_info.size()}\")\n",
    "        neg_items = self.item_embedding(neg_item)\n",
    "        print(f\"Neg Embedding Shape: {neg_items.size()}\")\n",
    "\n",
    "        # Create mask for seq_clicks, 0 for padding, 1 for real value.\n",
    "        print(f\"Seq Clicks Shape: {seq_clicks.size()}\")\n",
    "        print(f\"Seq Clicks: {seq_clicks}\")\n",
    "        seq_mask = [[1.0 if x != 0 else 0.0 for x in sequences] for sequences in seq_clicks]\n",
    "        # Convert seq_mask to torch float tensor.\n",
    "        print(f\"Seq Mask: {seq_mask}\")\n",
    "        print(f\"Seq Mask Shape: {len(seq_mask)}\")\n",
    "        seq_mask = torch.FloatTensor(seq_mask)\n",
    "        print(f\"Seq Mask Shape: {seq_mask.size()}\")\n",
    "        return seq_embed, pos_info, neg_items, seq_mask\n",
    "\n",
    "    def forward(self, batch, hidden):\n",
    "\n",
    "        seq_embed, pos_info, neg_info, seq_mask = self.embed_inputs(batch)\n",
    "        # mask\n",
    "        # mask = tf.cast(tf.not_equal(inputs['click_seq'], 0), dtype=tf.float32)  # (None, seq_len)\n",
    "        seq_embed = torch.mul(seq_embed, seq_mask.unsqueeze(-1))\n",
    "        # dropout\n",
    "        seq_info = self.dropout(seq_embed)\n",
    "        # gru\n",
    "        seq_info, hidden = self.gru_layers(seq_info, hidden)\n",
    "        # Removing sequences from the output of the GRU layer\n",
    "        seq_info = seq_info[:, -1, :]\n",
    "        seq_info = self.dense(seq_info)\n",
    "        seq_info = self.activation(seq_info)\n",
    "        # norm\n",
    "        # if self.use_l2norm:\n",
    "        #     pos_info = tf.math.l2_normalize(pos_info, axis=-1)\n",
    "        #     neg_info = tf.math.l2_normalize(neg_info, axis=-1)\n",
    "        #     seq_info = tf.math.l2_normalize(seq_info, axis=-1)\n",
    "        # calculate positive item scores and negative item scores\n",
    "        pos_scores = torch.sum(torch.mul(seq_info, pos_info), 1, keepdim=True)\n",
    "        neg_scores = torch.sum(torch.mul(seq_info.unsqueeze(1), neg_info), 2)\n",
    "        # loss\n",
    "        self.add_loss(get_loss(pos_scores, neg_scores, self.loss_name, self.gamma))\n",
    "        # logits = tf.concat([pos_scores, neg_scores], axis=-1)\n",
    "        # return logits\n",
    "        return pos_scores, neg_scores\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        pos_scores, neg_scores = self(batch, self.hidden)\n",
    "        loss = get_loss(pos_scores, neg_scores, self.loss_name, self.gamma)\n",
    "        # self.log(\n",
    "        #     \"train/mae\", mae, on_step=True, on_epoch=False, prog_bar=False\n",
    "        # )\n",
    "        \n",
    "        # self.log(\n",
    "        #     \"train/rmse\", rmse, on_step=True, on_epoch=False, prog_bar=False\n",
    "        # )\n",
    "        \n",
    "        # self.log(\"train/step_loss\", loss, on_step=True, on_epoch=False, prog_bar=False)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=0.0005)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        print(\"Loading datasets\")\n",
    "        self.train_dataset = MovieDataset(train_data)\n",
    "        self.val_dataset = MovieDataset(val_data)\n",
    "        self.test_dataset = MovieDataset(test_data)\n",
    "        print(\"Done\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=128,\n",
    "            shuffle=False,\n",
    "            num_workers=os.cpu_count(),\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=128,\n",
    "            shuffle=False,\n",
    "            num_workers=os.cpu_count(),\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=128,\n",
    "            shuffle=False,\n",
    "            num_workers=os.cpu_count(),\n",
    "        )\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        '''\n",
    "        Initialize the hidden state of the GRU\n",
    "        '''\n",
    "        try:\n",
    "            h0 = torch.zeros(2, 128, self.hidden_size).to(self._device)\n",
    "        except:\n",
    "            self._device = 'cpu'\n",
    "            h0 = torch.zeros(2, 128, self.hidden_size).to(self._device)\n",
    "        return h0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:105: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "\n",
      "  | Name           | Type      | Params\n",
      "---------------------------------------------\n",
      "0 | item_embedding | Embedding | 252 K \n",
      "1 | dropout        | Dropout   | 0     \n",
      "2 | gru_layers     | GRU       | 173 K \n",
      "---------------------------------------------\n",
      "426 K     Trainable params\n",
      "0         Non-trainable params\n",
      "426 K     Total params\n",
      "1.706     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets\n",
      "Done\n",
      "Epoch 0:   0%|          | 0/7673 [00:00<?, ?it/s] Seq Embedding Shape: torch.Size([128, 16, 64])\n",
      "Pos Embedding Shape: torch.Size([128, 64])\n",
      "Neg Embedding Shape: torch.Size([128, 4, 64])\n",
      "Seq Clicks Shape: torch.Size([128, 16])\n",
      "Seq Clicks: tensor([[ 231, 2836, 2694,  ..., 1821,  333,  719],\n",
      "        [  19,   65,  102,  ..., 1179, 2291,  535],\n",
      "        [ 927,  934, 1125,  ..., 2779, 3046, 2109],\n",
      "        ...,\n",
      "        [ 593,  223,  663,  ..., 1641, 1500, 2302],\n",
      "        [2683, 2706, 2572,  ..., 2688, 2959, 2333],\n",
      "        [2861, 1580, 2622,  ..., 2709,  586,    4]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m GRU4Rec(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_params)\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:696\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 696\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    697\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    698\u001b[0m )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    649\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    651\u001b[0m \u001b[39m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:735\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    731\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    732\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    733\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    734\u001b[0m )\n\u001b[0;32m--> 735\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    737\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    738\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1166\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1166\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1168\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1169\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1252\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1283\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   1282\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1283\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:271\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(\n\u001b[1;32m    268\u001b[0m     dataloader, batch_to_device\u001b[39m=\u001b[39mpartial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_call_strategy_hook, \u001b[39m\"\u001b[39m\u001b[39mbatch_to_device\u001b[39m\u001b[39m\"\u001b[39m, dataloader_idx\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    269\u001b[0m )\n\u001b[1;32m    270\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:203\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    202\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 203\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_loop\u001b[39m.\u001b[39;49mrun(kwargs)\n\u001b[1;32m    205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    207\u001b[0m \u001b[39m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py:87\u001b[0m, in \u001b[0;36mTrainingBatchLoop.advance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[1;32m     84\u001b[0m     optimizers \u001b[39m=\u001b[39m _get_active_optimizers(\n\u001b[1;32m     85\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39moptimizer_frequencies, kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbatch_idx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m     86\u001b[0m     )\n\u001b[0;32m---> 87\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_loop\u001b[39m.\u001b[39;49mrun(optimizers, kwargs)\n\u001b[1;32m     88\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_loop\u001b[39m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:201\u001b[0m, in \u001b[0;36mOptimizerLoop.advance\u001b[0;34m(self, optimizers, kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madvance\u001b[39m(\u001b[39mself\u001b[39m, optimizers: List[Tuple[\u001b[39mint\u001b[39m, Optimizer]], kwargs: OrderedDict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_kwargs(kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_idx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hiddens)\n\u001b[0;32m--> 201\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_optimization(kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizers[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptim_progress\u001b[39m.\u001b[39;49moptimizer_position])\n\u001b[1;32m    202\u001b[0m     \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[39m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[39m# would be skipped otherwise\u001b[39;00m\n\u001b[1;32m    205\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_idx] \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39masdict()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:248\u001b[0m, in \u001b[0;36mOptimizerLoop._run_optimization\u001b[0;34m(self, kwargs, optimizer)\u001b[0m\n\u001b[1;32m    240\u001b[0m         closure()\n\u001b[1;32m    242\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     \u001b[39m# the `batch_idx` is optional with inter-batch parallelism\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(optimizer, opt_idx, kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[1;32m    250\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     \u001b[39m# if no result, user decided to skip optimization\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39m# otherwise update running loss + reset accumulated loss\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     \u001b[39m# TODO: find proper way to handle updating running loss\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:358\u001b[0m, in \u001b[0;36mOptimizerLoop._optimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[1;32m    357\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[1;32m    359\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    360\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[1;32m    361\u001b[0m     batch_idx,\n\u001b[1;32m    362\u001b[0m     optimizer,\n\u001b[1;32m    363\u001b[0m     opt_idx,\n\u001b[1;32m    364\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    365\u001b[0m     on_tpu\u001b[39m=\u001b[39;49m\u001b[39misinstance\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49maccelerator, TPUAccelerator),\n\u001b[1;32m    366\u001b[0m     using_native_amp\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mamp_backend \u001b[39m==\u001b[39;49m AMPType\u001b[39m.\u001b[39;49mNATIVE),\n\u001b[1;32m    367\u001b[0m     using_lbfgs\u001b[39m=\u001b[39;49mis_lbfgs,\n\u001b[1;32m    368\u001b[0m )\n\u001b[1;32m    370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    371\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1550\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1547\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m   1549\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1550\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1552\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1553\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1705\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[1;32m   1624\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1625\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1632\u001b[0m     using_lbfgs: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1633\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1634\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \u001b[39m    Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m \u001b[39m    each optimizer.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1703\u001b[0m \n\u001b[1;32m   1704\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1705\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:168\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    167\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_idx, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[1;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:216\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39m\"\"\"Performs the actual optimizer step.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39m    **kwargs: Any extra arguments to ``optimizer.step``\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    215\u001b[0m model \u001b[39m=\u001b[39m model \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(model, optimizer, opt_idx, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:153\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, model, optimizer, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule):\n\u001b[1;32m    152\u001b[0m     closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, optimizer_idx, closure)\n\u001b[0;32m--> 153\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py:119\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m--> 119\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    121\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m    122\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:138\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, optimizer_idx, closure)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[1;32m    126\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    127\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m    131\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    132\u001b[0m     \u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer, optimizer_idx)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:132\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 132\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_fn()\n\u001b[1;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:407\u001b[0m, in \u001b[0;36mOptimizerLoop._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[39m\"\"\"Performs the actual train step with the tied hooks.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \n\u001b[1;32m    400\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39m    A ``ClosureResult`` containing the training step output.\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m training_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    408\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()\n\u001b[1;32m    410\u001b[0m model_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39m\"\u001b[39m\u001b[39mtraining_step_end\u001b[39m\u001b[39m\"\u001b[39m, training_step_output)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1704\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1701\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1704\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1706\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1707\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:358\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[1;32m    357\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TrainingStep)\n\u001b[0;32m--> 358\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn [14], line 117\u001b[0m, in \u001b[0;36mGRU4Rec.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [14], line 88\u001b[0m, in \u001b[0;36mGRU4Rec.forward\u001b[0;34m(self, batch, hidden)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, hidden):\n\u001b[0;32m---> 88\u001b[0m     seq_embed, pos_info, neg_info, seq_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# mask\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# mask = tf.cast(tf.not_equal(inputs['click_seq'], 0), dtype=tf.float32)  # (None, seq_len)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# seq_embed = tf.multiply(seq_embed, tf.expand_dims(mask, axis=-1))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# logits = tf.concat([pos_scores, neg_scores], axis=-1)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# return logits\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [14], line 80\u001b[0m, in \u001b[0;36mGRU4Rec.embed_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeq Clicks Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_clicks\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeq Clicks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_clicks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m seq_mask \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m seq_clicks]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Convert seq_mask to torch float tensor.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m seq_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(seq_mask)\n",
      "Cell \u001b[0;32mIn [14], line 80\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeq Clicks Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_clicks\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeq Clicks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_clicks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m seq_mask \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m seq_clicks]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Convert seq_mask to torch float tensor.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m seq_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(seq_mask)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "model = GRU4Rec(**model_params)\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
