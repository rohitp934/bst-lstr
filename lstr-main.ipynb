{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roro\\AppData\\Local\\Temp\\ipykernel_17340\\2876192146.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(\"data/ml-1m/ratings.dat\", sep=\"::\", names=[\"uid\", \"sid\", \"rating\", \"timestamp\"])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/ml-1m/ratings.dat\", sep=\"::\", names=[\"uid\", \"sid\", \"rating\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   sid  rating  timestamp\n",
       "0    1  1193       5  978300760\n",
       "1    1   661       3  978302109\n",
       "2    1   914       3  978301968\n",
       "3    1  3408       4  978300275\n",
       "4    1  2355       5  978824291"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting ratings to implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000836"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['rating'] >= 0]\n",
    "df.head()\n",
    "df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Triplets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   sid  rating  timestamp\n",
       "0    1  1193       5  978300760\n",
       "1    1   661       3  978302109\n",
       "2    1   914       3  978301968\n",
       "3    1  3408       4  978300275\n",
       "4    1  2355       5  978824291"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_sizes = df.groupby('sid').size()\n",
    "good_items = item_sizes.index[item_sizes >= 0]\n",
    "df = df[df['sid'].isin(good_items)]\n",
    "\n",
    "user_sizes = df.groupby('uid').size()\n",
    "good_users = user_sizes.index[user_sizes >= 5]\n",
    "df = df[df['uid'].isin(good_users)]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densifying index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1104</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>639</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>853</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3177</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2162</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   sid  rating  timestamp\n",
       "0    0  1104       5  978300760\n",
       "1    0   639       3  978302109\n",
       "2    0   853       3  978301968\n",
       "3    0  3177       4  978300275\n",
       "4    0  2162       5  978824291"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap = {u: i for i, u in enumerate(set(df['uid']))}\n",
    "smap = {s: i for i, s in enumerate(set(df['sid']))}\n",
    "df['uid'] = df['uid'].map(umap)\n",
    "df['sid'] = df['sid'].map(smap)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6040 3706\n"
     ]
    }
   ],
   "source": [
    "user_count = len(umap)\n",
    "item_count = len(smap)\n",
    "print(user_count, item_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete df if just training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataframe into train, test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:02<00:00, 2975.19it/s]\n"
     ]
    }
   ],
   "source": [
    "user_group = df.groupby('uid')\n",
    "user2items = user_group.progress_apply(lambda x: list(x.sort_values('timestamp')['sid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_count = len(umap)\n",
    "train, val, test = {}, {}, {}\n",
    "for user in range(user_count):\n",
    "    items = user2items[user]\n",
    "    train[user]= items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[2969, 1574, 957, 1178, 2147, 1658, 3177, 1117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1108, 1127, 1120, 2512, 1201, 2735, 1135, 110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[579, 2651, 3301, 1788, 1781, 1327, 1174, 1279...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[1120, 1025, 3235, 3294, 466, 253, 1106, 1108,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[2512, 858, 847, 346, 1158, 2007, 2651, 1050, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                                seq\n",
       "0     0  [2969, 1574, 957, 1178, 2147, 1658, 3177, 1117...\n",
       "1     1  [1108, 1127, 1120, 2512, 1201, 2735, 1135, 110...\n",
       "2     2  [579, 2651, 3301, 1788, 1781, 1327, 1174, 1279...\n",
       "3     3  [1120, 1025, 3235, 3294, 466, 253, 1106, 1108,...\n",
       "4     4  [2512, 858, 847, 346, 1158, 2007, 2651, 1050, ..."
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert train dict into a pandas series with two columns: \n",
    "train_df = pd.Series(train).to_frame(name=\"seq\")\n",
    "# Add a column user with the user id\n",
    "train_df['user'] = train_df.index\n",
    "# Make user column first\n",
    "train_df = train_df[['user', 'seq']]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21      91\n",
       "20      86\n",
       "23      81\n",
       "24      81\n",
       "22      77\n",
       "        ..\n",
       "903      1\n",
       "447      1\n",
       "582      1\n",
       "1323     1\n",
       "888      1\n",
       "Name: seq, Length: 743, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find users with sequence length < 25\n",
    "train_df['seq'].apply(len).value_counts(sort=True, ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040,)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_arange = np.arange(0, user_count)\n",
    "user_arange.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(user_arange, columns=['user'])\n",
    "train_df['seq'] = [[] for _ in range(user_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy indices to new dataframe\n",
    "\n",
    "val_df = pd.DataFrame(user_arange, columns=['user'])\n",
    "# Add new column seq\n",
    "# Add new column seq with empty lists\n",
    "val_df['seq'] = [[] for _ in range(user_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(user_arange, columns=['user'])\n",
    "test_df['seq'] = [[] for _ in range(user_count)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is method 1 of creating the val and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:02<00:00, 2839.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[2969, 1574, 957, 1178, 2147, 1658, 3177, 111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[1108, 1127, 1120, 2512, 1201, 2735, 1135, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[579, 2651, 3301, 1788, 1781, 1327, 1174, 127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[1120, 1025, 3235, 3294, 466, 253, 1106, 1108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[2512, 858, 847, 346, 1158, 2007, 2651, 1050,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                                seq\n",
       "0     0  [[2969, 1574, 957, 1178, 2147, 1658, 3177, 111...\n",
       "1     1  [[1108, 1127, 1120, 2512, 1201, 2735, 1135, 11...\n",
       "2     2  [[579, 2651, 3301, 1788, 1781, 1327, 1174, 127...\n",
       "3     3  [[1120, 1025, 3235, 3294, 466, 253, 1106, 1108...\n",
       "4     4  [[2512, 858, 847, 346, 1158, 2007, 2651, 1050,..."
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "\n",
    "max_len = 26\n",
    "\n",
    "def create_sequences(window_size, step_size):\n",
    "    for i in trange(0, user_count):\n",
    "        train_sequences = []\n",
    "        val_sequences = []\n",
    "        test_sequences = []\n",
    "        values = train[i]\n",
    "        start_index = 0\n",
    "        while True:\n",
    "            end_index = start_index + window_size\n",
    "            seq = values[start_index:end_index]\n",
    "            if len(seq) < window_size:\n",
    "                # If sequence length is less than half of the window size, dont use it\n",
    "                if len(seq) < window_size / 2:\n",
    "                    break\n",
    "                train_sequences.append(seq[:-2])\n",
    "                val_sequences.append(seq[-2:-1])\n",
    "                test_sequences.append(seq[-1:])\n",
    "                break\n",
    "            train_sequences.append(seq[:-2])\n",
    "            val_sequences.append(seq[-2:-1])\n",
    "            test_sequences.append(seq[-1:])\n",
    "            start_index += step_size\n",
    "        # Set the sequence to the correct row\n",
    "        train_df.at[i, 'seq'] = train_sequences\n",
    "        val_df.at[i, 'seq'] = val_sequences\n",
    "        test_df.at[i, 'seq'] = test_sequences\n",
    "\n",
    "\n",
    "\n",
    "create_sequences(max_len, max_len)\n",
    "# train_df['seq'] = train_df['seq'].progress_apply(lambda x: create_sequences(x, max_len, max_len))\n",
    "\n",
    "# Remove empty sequences\n",
    "train_df = train_df[train_df['seq'].map(len) > 0]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1025], [1727]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[2931], [258], [2128], [627], [1420]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[632], [101]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[2743]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[2511], [3550], [1563], [2947], [265], [347],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                                seq\n",
       "0     0                                   [[1025], [1727]]\n",
       "1     1             [[2931], [258], [2128], [627], [1420]]\n",
       "2     2                                     [[632], [101]]\n",
       "3     3                                           [[2743]]\n",
       "4     4  [[2511], [3550], [1563], [2947], [265], [347],..."
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[853], [1439]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[1155], [2120], [2166], [1273], [1737]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[699], [1900]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[1774]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[2140], [3384], [1547], [3043], [1603], [1325...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                                seq\n",
       "0     0                                    [[853], [1439]]\n",
       "1     1           [[1155], [2120], [2166], [1273], [1737]]\n",
       "2     2                                    [[699], [1900]]\n",
       "3     3                                           [[1774]]\n",
       "4     4  [[2140], [3384], [1547], [3043], [1603], [1325..."
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[2969, 1574, 957, 1178, 2147, 1658, 3177, 1117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[2592, 1195, 2557, 1154, 639, 2710, 517, 2898,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[1108, 1127, 1120, 2512, 1201, 2735, 1135, 110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[2889, 1259, 1106, 1777, 859, 1773, 1012, 1782...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[576, 2856, 1161, 1152, 3457, 1153, 1775, 2046...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38599</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1830, 1162, 1184, 1144, 1129, 1749, 1123, 103...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38600</th>\n",
       "      <td>6039</td>\n",
       "      <td>[863, 689, 1084, 1572, 1765, 1113, 869, 24, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38601</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1031, 976, 148, 3493, 3441, 1124, 2410, 2443,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38602</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1161, 1499, 2058, 28, 2246, 3313, 2711, 1132,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38603</th>\n",
       "      <td>6039</td>\n",
       "      <td>[521, 1181, 3508, 481, 1005, 2952, 2965, 2378,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38604 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user                                                seq\n",
       "0         0  [2969, 1574, 957, 1178, 2147, 1658, 3177, 1117...\n",
       "1         0  [2592, 1195, 2557, 1154, 639, 2710, 517, 2898,...\n",
       "2         1  [1108, 1127, 1120, 2512, 1201, 2735, 1135, 110...\n",
       "3         1  [2889, 1259, 1106, 1777, 859, 1773, 1012, 1782...\n",
       "4         1  [576, 2856, 1161, 1152, 3457, 1153, 1775, 2046...\n",
       "...     ...                                                ...\n",
       "38599  6039  [1830, 1162, 1184, 1144, 1129, 1749, 1123, 103...\n",
       "38600  6039  [863, 689, 1084, 1572, 1765, 1113, 869, 24, 10...\n",
       "38601  6039  [1031, 976, 148, 3493, 3441, 1124, 2410, 2443,...\n",
       "38602  6039  [1161, 1499, 2058, 28, 2246, 3313, 2711, 1132,...\n",
       "38603  6039  [521, 1181, 3508, 481, 1005, 2952, 2965, 2378,...\n",
       "\n",
       "[38604 rows x 2 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[[\"user\", \"seq\"]].explode(\"seq\", ignore_index=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1025]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[1727]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[2931]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[258]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[2128]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38599</th>\n",
       "      <td>6039</td>\n",
       "      <td>[2422]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38600</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1116]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38601</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1173]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38602</th>\n",
       "      <td>6039</td>\n",
       "      <td>[363]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38603</th>\n",
       "      <td>6039</td>\n",
       "      <td>[2709]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38604 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user     seq\n",
       "0         0  [1025]\n",
       "1         0  [1727]\n",
       "2         1  [2931]\n",
       "3         1   [258]\n",
       "4         1  [2128]\n",
       "...     ...     ...\n",
       "38599  6039  [2422]\n",
       "38600  6039  [1116]\n",
       "38601  6039  [1173]\n",
       "38602  6039   [363]\n",
       "38603  6039  [2709]\n",
       "\n",
       "[38604 rows x 2 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = val_df[[\"user\", \"seq\"]].explode(\"seq\", ignore_index=True)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[853]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[1439]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[1155]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[2120]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[2166]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38599</th>\n",
       "      <td>6039</td>\n",
       "      <td>[35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38600</th>\n",
       "      <td>6039</td>\n",
       "      <td>[2785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38601</th>\n",
       "      <td>6039</td>\n",
       "      <td>[931]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38602</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1537]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38603</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1618]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38604 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user     seq\n",
       "0         0   [853]\n",
       "1         0  [1439]\n",
       "2         1  [1155]\n",
       "3         1  [2120]\n",
       "4         1  [2166]\n",
       "...     ...     ...\n",
       "38599  6039    [35]\n",
       "38600  6039  [2785]\n",
       "38601  6039   [931]\n",
       "38602  6039  [1537]\n",
       "38603  6039  [1618]\n",
       "\n",
       "[38604 rows x 2 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df[[\"user\", \"seq\"]].explode(\"seq\", ignore_index=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is method 2 for creating val and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_count = len(umap)\n",
    "train, val, test = {}, {}, {}\n",
    "for user in range(user_count):\n",
    "    items = user2items[user]\n",
    "    train[user], val[user], test[user] = items[:-2], items[-2:-1], items[-1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(values, window_size, step_size):\n",
    "    sequences = []\n",
    "    start_index = 0\n",
    "    while True:\n",
    "        end_index = start_index + window_size\n",
    "        seq = values[start_index:end_index]\n",
    "        if len(seq) < window_size:\n",
    "            # If sequence length is less than half of the window size, dont use it\n",
    "            if len(seq) < window_size / 2:\n",
    "                break\n",
    "            sequences.append(seq)\n",
    "            break\n",
    "        sequences.append(seq)\n",
    "        start_index += step_size\n",
    "    return sequences\n",
    "\n",
    "train_df['seq'] = train_df['seq'].progress_apply(lambda x: create_sequences(x, max_len, max_len))\n",
    "\n",
    "# Remove empty sequences\n",
    "train_df = train_df[train_df['seq'].map(len) > 0]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **End of Method 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[2969, 1574, 957, 1178, 2147, 1658, 3177, 1117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[2592, 1195, 2557, 1154, 639, 2710, 517, 2898,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[1108, 1127, 1120, 2512, 1201, 2735, 1135, 110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[2889, 1259, 1106, 1777, 859, 1773, 1012, 1782...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[576, 2856, 1161, 1152, 3457, 1153, 1775, 2046...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38599</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1830, 1162, 1184, 1144, 1129, 1749, 1123, 103...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38600</th>\n",
       "      <td>6039</td>\n",
       "      <td>[863, 689, 1084, 1572, 1765, 1113, 869, 24, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38601</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1031, 976, 148, 3493, 3441, 1124, 2410, 2443,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38602</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1161, 1499, 2058, 28, 2246, 3313, 2711, 1132,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38603</th>\n",
       "      <td>6039</td>\n",
       "      <td>[521, 1181, 3508, 481, 1005, 2952, 2965, 2378,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38604 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user                                                seq\n",
       "0         0  [2969, 1574, 957, 1178, 2147, 1658, 3177, 1117...\n",
       "1         0  [2592, 1195, 2557, 1154, 639, 2710, 517, 2898,...\n",
       "2         1  [1108, 1127, 1120, 2512, 1201, 2735, 1135, 110...\n",
       "3         1  [2889, 1259, 1106, 1777, 859, 1773, 1012, 1782...\n",
       "4         1  [576, 2856, 1161, 1152, 3457, 1153, 1775, 2046...\n",
       "...     ...                                                ...\n",
       "38599  6039  [1830, 1162, 1184, 1144, 1129, 1749, 1123, 103...\n",
       "38600  6039  [863, 689, 1084, 1572, 1765, 1113, 869, 24, 10...\n",
       "38601  6039  [1031, 976, 148, 3493, 3441, 1124, 2410, 2443,...\n",
       "38602  6039  [1161, 1499, 2058, 28, 2246, 3313, 2711, 1132,...\n",
       "38603  6039  [521, 1181, 3508, 481, 1005, 2952, 2965, 2378,...\n",
       "\n",
       "[38604 rows x 2 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find a user with a sequence length < 25\n",
    "train_df[train_df['seq'].apply(len) < 25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = {\n",
    "#     'val': val,\n",
    "#     'test': test,\n",
    "#     'umap': umap,\n",
    "#     'smap': smap\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets as pickle\n",
    "train_df.to_pickle(\"data/lstr/train.pkl\")\n",
    "val_df.to_pickle(\"data/lstr/val.pkl\")\n",
    "test_df.to_pickle(\"data/lstr/test.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_name = '{}_min_rating{}-min_uc{}-min_sc{}-split{}_except_train' \\\n",
    "#             .format('ml-1m', 0, 5, 0, 'leave_one_out')\n",
    "\n",
    "# with open('data/lstr/{}.pkl'.format(folder_name), 'wb') as f:\n",
    "#     pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get negative train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "dataset_folder = Path('data/')\n",
    "dataset_filename = '{}_min_rating{}-min_uc{}-min_sc{}-split{}'.format('ml-1m', 3, 5, 0, 'leave_one_out')\n",
    "dataset_file = dataset_folder.joinpath(dataset_filename + '.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset: dict[str, dict[str, list[int]]] = pickle.load(open(dataset_file, 'rb'))\n",
    "train_df: pd.DataFrame = pd.read_pickle(dataset_folder.joinpath('lstr/train.pkl'))\n",
    "val_df: pd.DataFrame = pd.read_pickle(dataset_folder.joinpath('lstr/val.pkl'))\n",
    "test_df: pd.DataFrame = pd.read_pickle(dataset_folder.joinpath('lstr/test.pkl'))\n",
    "# val = dataset['val']\n",
    "# test = dataset['test']\n",
    "# umap = dataset['umap']\n",
    "# smap = dataset['smap']\n",
    "# user_count = len(umap)\n",
    "# item_count = len(smap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "\n",
    "def generate_negative_samples(seed: int, sample_size: int = 100) -> dict[str, list[int]]:\n",
    "    np.random.seed(seed)\n",
    "    negative_samples = {}\n",
    "    # If sample size is 0 return;\n",
    "    if sample_size == 0: return\n",
    "    for row in trange(len(train_df)):\n",
    "        seen = set(train_df.iloc[row]['seq'])\n",
    "        seen.update(val_df.iloc[row]['seq'])\n",
    "        seen.update(test_df.iloc[row]['seq'])\n",
    "        \n",
    "        samples = []\n",
    "        for _ in range(sample_size):\n",
    "            item = np.random.choice(item_count) + 1\n",
    "            while item in seen or item in samples:\n",
    "                item = np.random.choice(item_count) + 1\n",
    "            samples.append(item)\n",
    "        \n",
    "        negative_samples[row] = samples\n",
    "    \n",
    "    return negative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38604/38604 [00:18<00:00, 2134.35it/s]\n"
     ]
    }
   ],
   "source": [
    "negative_train_samples = generate_negative_samples(0, 0)\n",
    "negative_test_samples = generate_negative_samples(42, 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Negative train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_test_save_file_path = 'lstr/{}-sample_size{}-seed{}-{}.pkl'.format('random', 26, 42, 'test')\n",
    "negative_test_save_file = dataset_folder.joinpath(negative_test_save_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with negative_test_save_file.open('wb') as f:\n",
    "    pickle.dump(negative_test_samples, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with negative_test_save_file.open('rb') as f:\n",
    "    negative_test_samples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(negative_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTrainDataset(data_utils.Dataset):\n",
    "    def __init__(self, max_len: int, mask_prob: float, mask_token: int, num_items: int, rng: random.Random, long_len: int):\n",
    "        # self.users = sorted(self.u2seq.keys())\n",
    "        self.max_len = max_len\n",
    "        self.train_df = pd.read_pickle('data/lstr/train.pkl')\n",
    "        self.mask_prob = mask_prob\n",
    "        self.mask_token = mask_token\n",
    "        self.num_items = num_items\n",
    "        self.rng = rng\n",
    "        self.long_len = long_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_df)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        seq = self.train_df.seq[index]\n",
    "\n",
    "        tokens: list[int] = []\n",
    "        labels: list[int] = []\n",
    "        for s in seq:\n",
    "            prob = self.rng.random()\n",
    "            if prob < self.mask_prob:\n",
    "                prob /= self.mask_prob\n",
    "\n",
    "                if prob < 0.8:\n",
    "                    tokens.append(self.mask_token)\n",
    "                elif prob < 0.9:\n",
    "                    tokens.append(self.rng.randint(1, self.num_items))\n",
    "                else:\n",
    "                    tokens.append(s)\n",
    "\n",
    "                labels.append(s)\n",
    "            else:\n",
    "                tokens.append(s)\n",
    "                labels.append(0)\n",
    "\n",
    "        # May not need this since the sequences are already cut.\n",
    "        # tokens = tokens[-self.max_len:]\n",
    "        # labels = labels[-self.max_len:]\n",
    "\n",
    "        mask_len = self.max_len - len(tokens)\n",
    "\n",
    "        tokens = [0] * mask_len + tokens\n",
    "        labels = [0] * mask_len + labels\n",
    "\n",
    "        # Split the sequences into two parts.\n",
    "        # Long and short sequence.\n",
    "        long_tokens = tokens[:self.long_len]\n",
    "        short_tokens = tokens[self.long_len:]\n",
    "\n",
    "        return torch.LongTensor(long_tokens), torch.LongTensor(short_tokens), torch.LongTensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = BertTrainDataset(26, 0.15, item_count+1, item_count, random.Random(0), 18)\n",
    "train_ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two lines of thought:\n",
    "\n",
    "#### 1. We could use **leave_one_out** on each sequence generated and get a validation and test set for each row in `train_df`.\n",
    "- For example, we could have:\n",
    "  - `seq_length = 26`\n",
    "  - `train_short_len = 6`\n",
    "  - `train_long_len = 18`\n",
    "  - `val_len = 1`\n",
    "  - `test_len = 1`\n",
    "\n",
    "#### 2. We could use **leave_one_out** on the entire train set per user before generating sequences we create a validation and test set. This would mean using the same validation and test for all sequences for a given user.\n",
    "- For example, we could have:\n",
    "  - `seq_length = 25`\n",
    "  - `train_short_len = 5`\n",
    "  - `train_long_len = 20`\n",
    "  - `val_len = 1` taken from the entire train set\n",
    "  - `test_len = 1` taken from the entire train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Dataset (Val and Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEvalDataset(data_utils.Dataset):\n",
    "    def __init__(self, answer: str, max_len: int, mask_token: int, negative_samples: dict[str, list[int]], long_len: int) -> None:\n",
    "        self.train_df = pd.read_pickle('data/lstr/train.pkl')\n",
    "        if answer == 'val':\n",
    "            self.df = pd.read_pickle('data/lstr/val.pkl')\n",
    "        elif answer == 'test':\n",
    "            self.df = pd.read_pickle('data/lstr/test.pkl')\n",
    "        self.max_len = max_len\n",
    "        self.mask_token = mask_token\n",
    "        self.negative_samples = negative_samples\n",
    "        self.long_len = long_len\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.LongTensor, torch.LongTensor, torch.LongTensor]:\n",
    "        \n",
    "        seq = self.train_df.iloc[index]['seq']\n",
    "        answer = self.df.iloc[index]['seq']\n",
    "        negs = self.negative_samples[index]\n",
    "\n",
    "        candidates = answer + negs\n",
    "        labels = [1] * len(answer) + [0] * len(negs)\n",
    "\n",
    "        seq = seq + [self.mask_token]\n",
    "        seq = seq[-self.max_len:]\n",
    "        padding_len = self.max_len - len(seq)\n",
    "        seq = [0] * padding_len + seq\n",
    "\n",
    "        long_seq = seq[:self.long_len]\n",
    "        short_seq = seq[self.long_len:]\n",
    "\n",
    "        return torch.LongTensor(long_seq), torch.LongTensor(short_seq), torch.LongTensor(candidates), torch.LongTensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = BertEvalDataset('val', 26, item_count+1, negative_test_samples, 18)\n",
    "test_ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random_seed_as(random_seed: int) -> None:\n",
    "    random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(pl.LightningModule):\n",
    "    def __init__(self, max_len: int, d_model: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        self.pe = nn.Embedding(max_len, d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = x.size(0)\n",
    "        return self.pe.weight.unsqueeze(0).repeat(batch_size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEmbedding(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    BERT Embedding which is consisted with under features\n",
    "        1. TokenEmbedding : normal embedding matrix\n",
    "        2. PositionalEmbedding : adding positional information using sin, cos\n",
    "        2. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2)\n",
    "        sum of all these features are output of BERTEmbedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size: int, embed_size: int, max_len: int, dropout: float = 0.1) -> None:\n",
    "        \"\"\"\n",
    "        :param vocab_size: total vocab size\n",
    "        :param embed_size: embedding size of token embedding\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.token = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_size)\n",
    "        self.position = PositionalEmbedding(max_len=max_len, d_model=embed_size)\n",
    "        # self.segment = SegmentEmbedding(embed_size=self.token.embedding_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "    def forward(self, sequence: torch.Tensor) -> torch.Tensor:\n",
    "        x: torch.Tensor = self.token(sequence) + self.position(sequence)  # + self.segment(segment_label)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_template(args):\n",
    "    if args.template is None:\n",
    "        return\n",
    "\n",
    "    elif args.template.startswith('train_bert'):\n",
    "        args.mode = 'train'\n",
    "\n",
    "        args.dataset_code = 'ml-' + input('Input 1 for ml-1m, 20 for ml-20m: ') + 'm'\n",
    "        args.min_rating = 0 if args.dataset_code == 'ml-1m' else 4\n",
    "        args.min_uc = 5\n",
    "        args.min_sc = 0\n",
    "        args.split = 'leave_one_out'\n",
    "\n",
    "        args.dataloader_code = 'bert'\n",
    "        batch = 64\n",
    "        args.train_batch_size = batch\n",
    "        args.val_batch_size = batch\n",
    "        args.test_batch_size = batch\n",
    "\n",
    "        args.train_negative_sampler_code = 'random'\n",
    "        args.train_negative_sample_size = 0\n",
    "        args.train_negative_sampling_seed = 0\n",
    "        args.test_negative_sampler_code = 'random'\n",
    "        args.test_negative_sample_size = 100\n",
    "        args.test_negative_sampling_seed = 98765\n",
    "\n",
    "        args.trainer_code = 'bert'\n",
    "        args.device = 'cuda'\n",
    "        args.num_gpu = 1\n",
    "        args.device_idx = '0'\n",
    "        args.optimizer = 'Adam'\n",
    "        args.lr = 0.001\n",
    "        args.enable_lr_schedule = True\n",
    "        args.decay_step = 25\n",
    "        args.gamma = 1.0\n",
    "        args.num_epochs = 100 if args.dataset_code == 'ml-1m' else 200\n",
    "        args.metric_ks = [1, 5, 10, 20]\n",
    "        args.best_metric = 'NDCG@10'\n",
    "\n",
    "        args.model_code = 'bert'\n",
    "        args.model_init_seed = 0\n",
    "\n",
    "        args.bert_dropout = 0.1\n",
    "        args.bert_hidden_units = 256\n",
    "        args.bert_mask_prob = 0.15\n",
    "        args.bert_max_len = 100\n",
    "        args.bert_num_blocks = 2\n",
    "        args.bert_num_heads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import NumberType\n",
    "\n",
    "\n",
    "def recalls_and_ndcgs_for_ks(scores: torch.Tensor, labels: torch.Tensor, ks: list[int]):\n",
    "    metrics: dict[str, NumberType] = {}\n",
    "\n",
    "    # Why is this being done?\n",
    "    # scores = scores\n",
    "    # labels = labels\n",
    "    answer_count = labels.sum(1)\n",
    "\n",
    "    labels_float = labels.float()\n",
    "    rank = (-scores).argsort(dim=1)\n",
    "    cut = rank\n",
    "    for k in sorted(ks, reverse=True):\n",
    "        cut = cut[:, :k]\n",
    "        hits = labels_float.gather(1, cut)\n",
    "        \"\"\"\n",
    "            Recall at k is the proportion of relevant items found in the top-k recommendations.\n",
    "            Recall@k = (# of recommended items @k that are relevant) / (total # of relevant items)\n",
    "        \"\"\"\n",
    "        numerator = hits.sum(1)\n",
    "        denominator = torch.min(torch.Tensor([k]).to(labels.device), labels.sum(1).float())\n",
    "        metrics['Recall@%d' % k] = \\\n",
    "            (numerator / denominator).mean().cpu().item()\n",
    "\n",
    "        \"\"\"\n",
    "            NDCG at k is the average of the normalized DCG scores of the top-k recommendations.\n",
    "            NDCG@k = DCG@k / IDCG@k\n",
    "            DCG@K = SUM( recc_i / log2(i + 1))\n",
    "            IDCG@K = SUM( real_i / log2(i + 1))\n",
    "        \"\"\"\n",
    "        position = torch.arange(2, 2+k)\n",
    "        weights = 1 / torch.log2(position.float())\n",
    "        # Discounted cumulative gain at k\n",
    "        dcg = (hits * weights.to(hits.device)).sum(1)\n",
    "        # Ideal discounted cumulative gain at k\n",
    "        # idcg = (labels_float * weights.to(labels_float.device)).sum(1)\n",
    "        idcg = torch.Tensor([weights[:min(int(n), k)].sum()\n",
    "                            for n in answer_count]).to(dcg.device)\n",
    "        # What is the above code doing\n",
    "        ndcg = (dcg / idcg).mean()\n",
    "        metrics['NDCG@%d' % k] = ndcg.cpu().item()\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(pl.LightningModule):\n",
    "    def __init__(self, args: dotdict):\n",
    "        super().__init__()\n",
    "\n",
    "        fix_random_seed_as(args.model_init_seed)\n",
    "        # self.init_weights()\n",
    "\n",
    "        self.args = args\n",
    "        long_len: int = args.bert_long_len\n",
    "        short_len: int = args.bert_short_len\n",
    "        num_items: int = args.num_items\n",
    "        n_layers: int = args.bert_num_blocks\n",
    "        self.heads: int = args.bert_num_heads\n",
    "        vocab_size: int = num_items + 2\n",
    "        hidden: int = args.bert_hidden_units\n",
    "        self.hidden = hidden\n",
    "        self.metric_ks = args.metric_ks\n",
    "        dropout: float = args.bert_dropout\n",
    "        self.ce = nn.CrossEntropyLoss(ignore_index=0)\n",
    "        # embedding for BERT, sum of positional, segment, token embeddings\n",
    "        self.long_embedding = BERTEmbedding(\n",
    "            vocab_size=vocab_size, embed_size=self.hidden, max_len=long_len, dropout=dropout)\n",
    "        self.short_embedding = BERTEmbedding(\n",
    "            vocab_size=vocab_size, embed_size=self.hidden, max_len=short_len, dropout=dropout)\n",
    "        # multi-layers transformer blocks, deep network\n",
    "        self.encoder = nn.TransformerEncoderLayer(hidden, self.heads, hidden * 4, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder, n_layers)\n",
    "        self.out = nn.Linear(self.hidden, num_items + 1)\n",
    "\n",
    "    def forward(self, long_seq: torch.Tensor, short_seq: torch.Tensor) -> torch.Tensor:\n",
    "        long_mask = (long_seq == 0).unsqueeze(1).repeat(self.heads, long_seq.size(1), 1)\n",
    "        long_seq = self.long_embedding(long_seq)\n",
    "        long_output: torch.Tensor = self.transformer(long_seq, long_mask)\n",
    "\n",
    "        short_mask = (short_seq == 0).unsqueeze(1).repeat(self.heads, short_seq.size(1), 1)\n",
    "        short_seq = self.short_embedding(short_seq)\n",
    "        short_output: torch.Tensor = self.transformer(short_seq, short_mask)\n",
    "\n",
    "        output = torch.cat([long_output, short_output], dim=1)\n",
    "\n",
    "        # output = output.masked_fill(torch.isnan(output), 0)\n",
    "        return self.out(output)\n",
    "\n",
    "    def init_weights(self):\n",
    "        pass\n",
    "\n",
    "    def training_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        batch_size = batch[0].size(0)\n",
    "        long_seq, short_seq, labels = batch\n",
    "        logits: torch.Tensor = self(long_seq, short_seq)\n",
    "\n",
    "        logits = logits.view(-1, logits.size(-1))\n",
    "        labels = labels.view(-1)\n",
    "        loss: torch.Tensor = self.ce(logits, labels)\n",
    "        # log_data = {\n",
    "        #     'state_dict': (self._create_state_dict()),\n",
    "        #     \"train/ce\": loss.item()\n",
    "        # }\n",
    "        self.log(\n",
    "            \"train/ce\", loss, on_step=True, on_epoch=False, prog_bar=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: tuple[torch.Tensor, torch.Tensor, torch.Tensor], batch_idx: int) -> dict[str, NumberType]:\n",
    "        long_seq, short_seq, candidates, labels = batch\n",
    "        scores: torch.Tensor = self(long_seq, short_seq)\n",
    "        scores = scores[:, -1, :]\n",
    "        scores = scores.gather(1, candidates)\n",
    "        metrics = recalls_and_ndcgs_for_ks(scores, labels, self.metric_ks)\n",
    "\n",
    "        self.log_dict(metrics, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch: tuple[torch.Tensor, torch.Tensor, torch.Tensor], batch_idx: int) -> dict[str, NumberType]:\n",
    "        long_seq, short_seq, candidates, labels = batch\n",
    "        scores: torch.Tensor = self(long_seq, short_seq)\n",
    "        scores = scores[:, -1, :]\n",
    "        scores = scores.gather(1, candidates)\n",
    "        metrics = recalls_and_ndcgs_for_ks(scores, labels, self.metric_ks)\n",
    "\n",
    "        self.log_dict(metrics, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        return metrics\n",
    "\n",
    "    def validation_epoch_end(self, outputs: list[dict[str, NumberType]]) -> None:\n",
    "        # outputs is a list of dicts\n",
    "        avg_metrics = {}\n",
    "        for metric in outputs[0].keys():\n",
    "            avg_metrics[metric] = torch.mean(torch.FloatTensor([x[metric] for x in outputs]))\n",
    "        \n",
    "        self.log_dict(avg_metrics, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "\n",
    "\n",
    "        # for metric in outputs[0].keys():\n",
    "        #     self.log(metric, torch.mean(torch.stack(\n",
    "        #         [output[metric] for output in outputs])), on_step=False, on_epoch=True, prog_bar=False)\n",
    "    \n",
    "    def test_epoch_end(self, outputs: list[dict[str, NumberType]]) -> None:\n",
    "        # outputs is a list of dicts\n",
    "        metric_names = outputs[0].keys()\n",
    "        avg_metrics = dict.fromkeys(metric_names, [])\n",
    "        for output in outputs:\n",
    "            for metric_name in metric_names:\n",
    "                avg_metrics[metric_name].append(output[metric_name])\n",
    "        \n",
    "        for metric_name in metric_names:\n",
    "            avg_metrics[metric_name] = torch.mean(torch.stack(avg_metrics[metric_name]))\n",
    "        \n",
    "        self.log_dict(avg_metrics, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        # for metric in outputs[0].keys():\n",
    "        #     self.log(metric, torch.mean(torch.stack(\n",
    "        #         [output[metric] for output in outputs])), on_step=False, on_epoch=True, prog_bar=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.args['optimizer'].lower() == 'adam':\n",
    "            return torch.optim.Adam(self.parameters(), lr=self.args['lr'], weight_decay=self.args['weight_decay'])\n",
    "        elif self.args['optimizer'].lower() == 'sgd':\n",
    "            return torch.optim.SGD(self.parameters(), lr=self.args['lr'], weight_decay=self.args['weight_decay'], momentum=self.args['momentum'])\n",
    "        else:\n",
    "            raise ValueError('Optimizer not supported')\n",
    "\n",
    "    def _create_state_dict(self):\n",
    "        return {\n",
    "            'model_state_dict': self.model.module.state_dict() if self.is_parallel else self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "        }\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = BertTrainDataset(26, 0.15, item_count+1, item_count, random.Random(0), 18)\n",
    "        self.val_dataset = BertEvalDataset('val', 26, item_count+1, negative_test_samples, 18)\n",
    "        self.test_dataset = BertEvalDataset('test', 26, item_count+1, negative_test_samples, 18)\n",
    "\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return data_utils.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=128,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "            num_workers=16\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return data_utils.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=128,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "            num_workers=16\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return data_utils.DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=128,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "            num_workers=16\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'bert_max_len': 26,\n",
    "    'bert_long_len': 18,\n",
    "    'bert_short_len': 8,\n",
    "    'num_items': item_count,\n",
    "    'bert_num_blocks': 2,\n",
    "    'bert_num_heads': 4,\n",
    "    'bert_hidden_units': 256,\n",
    "    'bert_dropout': 0.1,\n",
    "    'model_init_seed': 42,\n",
    "    'bert_mask_prob': 0.15,\n",
    "    'metric_ks': [1, 5, 10, 20],\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 0.0,\n",
    "    'optimizer': 'Adam',\n",
    "}\n",
    "\n",
    "args = dotdict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | ce              | CrossEntropyLoss        | 0     \n",
      "1 | long_embedding  | BERTEmbedding           | 953 K \n",
      "2 | short_embedding | BERTEmbedding           | 951 K \n",
      "3 | encoder         | TransformerEncoderLayer | 789 K \n",
      "4 | transformer     | TransformerEncoder      | 1.6 M \n",
      "5 | out             | Linear                  | 952 K \n",
      "------------------------------------------------------------\n",
      "5.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.2 M     Total params\n",
      "20.909    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.profiler import SimpleProfiler\n",
    "model = BERT(args)\n",
    "profiler = SimpleProfiler()\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=1, max_epochs=5, profiler=profiler)\n",
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 ('bst': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ca0676aa18c95b2f4ddbcd7227ae51f1b24dbd48c44e8096aadec2eff2cfaf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
