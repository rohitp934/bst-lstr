{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Need to work on EvalDataset to work with two sequences. Figure it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roro\\AppData\\Local\\Temp\\ipykernel_4108\\2876192146.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(\"data/ml-1m/ratings.dat\", sep=\"::\", names=[\"uid\", \"sid\", \"rating\", \"timestamp\"])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/ml-1m/ratings.dat\", sep=\"::\", names=[\"uid\", \"sid\", \"rating\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   sid  rating  timestamp\n",
       "0    1  1193       5  978300760\n",
       "1    1   661       3  978302109\n",
       "2    1   914       3  978301968\n",
       "3    1  3408       4  978300275\n",
       "4    1  2355       5  978824291"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting ratings to implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000836"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['rating'] >= 0]\n",
    "df.head()\n",
    "df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Triplets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   sid  rating  timestamp\n",
       "0    1  1193       5  978300760\n",
       "1    1   661       3  978302109\n",
       "2    1   914       3  978301968\n",
       "3    1  3408       4  978300275\n",
       "4    1  2355       5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_sizes = df.groupby('sid').size()\n",
    "good_items = item_sizes.index[item_sizes >= 0]\n",
    "df = df[df['sid'].isin(good_items)]\n",
    "\n",
    "user_sizes = df.groupby('uid').size()\n",
    "good_users = user_sizes.index[user_sizes >= 5]\n",
    "df = df[df['uid'].isin(good_users)]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densifying index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>sid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1104</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>639</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>853</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3177</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2162</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   sid  rating  timestamp\n",
       "0    0  1104       5  978300760\n",
       "1    0   639       3  978302109\n",
       "2    0   853       3  978301968\n",
       "3    0  3177       4  978300275\n",
       "4    0  2162       5  978824291"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap = {u: i for i, u in enumerate(set(df['uid']))}\n",
    "smap = {s: i for i, s in enumerate(set(df['sid']))}\n",
    "df['uid'] = df['uid'].map(umap)\n",
    "df['sid'] = df['sid'].map(smap)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataframe into train, test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:01<00:00, 5587.40it/s]\n"
     ]
    }
   ],
   "source": [
    "user_group = df.groupby('uid')\n",
    "user2items = user_group.progress_apply(lambda x: list(x.sort_values('timestamp')['sid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid\n",
       "0       [2969, 1574, 957, 1178, 2147, 1658, 3177, 1117...\n",
       "1       [1108, 1127, 1120, 2512, 1201, 2735, 1135, 110...\n",
       "2       [579, 2651, 3301, 1788, 1781, 1327, 1174, 1279...\n",
       "3       [1120, 1025, 3235, 3294, 466, 253, 1106, 1108,...\n",
       "4       [2512, 858, 847, 346, 1158, 2007, 2651, 1050, ...\n",
       "                              ...                        \n",
       "6035    [1574, 2183, 3206, 2235, 1703, 2298, 2622, 248...\n",
       "6036    [1702, 1848, 1175, 672, 3275, 548, 2932, 802, ...\n",
       "6037    [859, 3165, 1120, 1965, 346, 1288, 1007, 1066,...\n",
       "6038    [107, 275, 1886, 869, 1139, 2917, 2809, 886, 2...\n",
       "6039    [802, 2191, 579, 1781, 1839, 559, 2895, 3272, ...\n",
       "Length: 6040, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user2items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_count = len(umap)\n",
    "train, val, test = {}, {}, {}\n",
    "for user in range(user_count):\n",
    "    items = user2items[user]\n",
    "    train[user], val[user], test[user] = items[:-2], items[-2:-1], items[-1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[2969, 1574, 957, 1178, 2147, 1658, 3177, 1117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1108, 1127, 1120, 2512, 1201, 2735, 1135, 110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[579, 2651, 3301, 1788, 1781, 1327, 1174, 1279...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[1120, 1025, 3235, 3294, 466, 253, 1106, 1108,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[2512, 858, 847, 346, 1158, 2007, 2651, 1050, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                                seq\n",
       "0     0  [2969, 1574, 957, 1178, 2147, 1658, 3177, 1117...\n",
       "1     1  [1108, 1127, 1120, 2512, 1201, 2735, 1135, 110...\n",
       "2     2  [579, 2651, 3301, 1788, 1781, 1327, 1174, 1279...\n",
       "3     3  [1120, 1025, 3235, 3294, 466, 253, 1106, 1108,...\n",
       "4     4  [2512, 858, 847, 346, 1158, 2007, 2651, 1050, ..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert train dict into a pandas series with two columns: \n",
    "train_df = pd.Series(train).to_frame(name=\"seq\")\n",
    "# Add a column user with the user id\n",
    "train_df['user'] = train_df.index\n",
    "# Make user column first\n",
    "train_df = train_df[['user', 'seq']]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19      91\n",
       "18      86\n",
       "21      81\n",
       "22      81\n",
       "20      77\n",
       "        ..\n",
       "901      1\n",
       "445      1\n",
       "580      1\n",
       "1321     1\n",
       "886      1\n",
       "Name: seq, Length: 743, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find users with sequence length < 25\n",
    "train_df['seq'].apply(len).value_counts(sort=True, ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:00<00:00, 183048.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[2969, 1574, 957, 1178, 2147, 1658, 3177, 111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[1108, 1127, 1120, 2512, 1201, 2735, 1135, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[579, 2651, 3301, 1788, 1781, 1327, 1174, 127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[1120, 1025, 3235, 3294, 466, 253, 1106, 1108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[2512, 858, 847, 346, 1158, 2007, 2651, 1050,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                                seq\n",
       "0     0  [[2969, 1574, 957, 1178, 2147, 1658, 3177, 111...\n",
       "1     1  [[1108, 1127, 1120, 2512, 1201, 2735, 1135, 11...\n",
       "2     2  [[579, 2651, 3301, 1788, 1781, 1327, 1174, 127...\n",
       "3     3  [[1120, 1025, 3235, 3294, 466, 253, 1106, 1108...\n",
       "4     4  [[2512, 858, 847, 346, 1158, 2007, 2651, 1050,..."
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_sequences(values, window_size, step_size):\n",
    "    sequences = []\n",
    "    start_index = 0\n",
    "    while True:\n",
    "        end_index = start_index + window_size\n",
    "        seq = values[start_index:end_index]\n",
    "        if len(seq) < window_size:\n",
    "            # If sequence length is less than half of the window size, dont use it\n",
    "            if len(seq) < window_size / 2:\n",
    "                break\n",
    "            sequences.append(seq)\n",
    "            break\n",
    "        sequences.append(seq)\n",
    "        start_index += step_size\n",
    "    return sequences\n",
    "\n",
    "train_df['seq'] = train_df['seq'].progress_apply(lambda x: create_sequences(x, max_len, max_len))\n",
    "\n",
    "# Remove empty sequences\n",
    "train_df = train_df[train_df['seq'].map(len) > 0]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[2969, 1574, 957, 1178, 2147, 1658, 3177, 1117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[853, 2592, 1195, 2557, 1154, 639, 2710, 517, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[1108, 1127, 1120, 2512, 1201, 2735, 1135, 110...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[1155, 2889, 1259, 1106, 1777, 859, 1773, 1012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[258, 2120, 576, 2856, 1161, 1152, 3457, 1153,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39534</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1159, 1188, 78, 842, 2523, 2918, 3186, 2422, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39535</th>\n",
       "      <td>6039</td>\n",
       "      <td>[3238, 2462, 324, 838, 855, 917, 2762, 1500, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39536</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1152, 2892, 690, 1256, 1786, 1091, 754, 735, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39537</th>\n",
       "      <td>6039</td>\n",
       "      <td>[2108, 2867, 3575, 2173, 1720, 1099, 1732, 346...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39538</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1887, 1767, 1121, 2374, 1236, 892, 2520, 1536...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39539 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user                                                seq\n",
       "0         0  [2969, 1574, 957, 1178, 2147, 1658, 3177, 1117...\n",
       "1         0  [853, 2592, 1195, 2557, 1154, 639, 2710, 517, ...\n",
       "2         1  [1108, 1127, 1120, 2512, 1201, 2735, 1135, 110...\n",
       "3         1  [1155, 2889, 1259, 1106, 1777, 859, 1773, 1012...\n",
       "4         1  [258, 2120, 576, 2856, 1161, 1152, 3457, 1153,...\n",
       "...     ...                                                ...\n",
       "39534  6039  [1159, 1188, 78, 842, 2523, 2918, 3186, 2422, ...\n",
       "39535  6039  [3238, 2462, 324, 838, 855, 917, 2762, 1500, 1...\n",
       "39536  6039  [1152, 2892, 690, 1256, 1786, 1091, 754, 735, ...\n",
       "39537  6039  [2108, 2867, 3575, 2173, 1720, 1099, 1732, 346...\n",
       "39538  6039  [1887, 1767, 1121, 2374, 1236, 892, 2520, 1536...\n",
       "\n",
       "[39539 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[[\"user\", \"seq\"]].explode(\"seq\", ignore_index=True)\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>[699, 1826, 2277, 1934, 982, 538, 2415, 2530, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>[1120, 1025, 3235, 3294, 466, 253, 1106, 1108,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>[2078, 1575, 188, 1546, 2864, 1741, 2520, 3042...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>[1767, 3360, 3370, 1837, 373, 259, 358, 2859, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9</td>\n",
       "      <td>[1915, 713, 1160, 1148, 958, 970, 1142, 3120, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39457</th>\n",
       "      <td>6030</td>\n",
       "      <td>[858, 1178, 346, 2511, 2599, 3216, 1414, 1205,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39464</th>\n",
       "      <td>6033</td>\n",
       "      <td>[906, 1247, 2914, 513, 334, 852, 2521, 1485, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39519</th>\n",
       "      <td>6037</td>\n",
       "      <td>[859, 3165, 1120, 1965, 346, 1288, 1007, 1066,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39524</th>\n",
       "      <td>6038</td>\n",
       "      <td>[843, 1192, 852, 1014, 1784, 2024, 889, 2026, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39538</th>\n",
       "      <td>6039</td>\n",
       "      <td>[1887, 1767, 1121, 2374, 1236, 892, 2520, 1536...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2978 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user                                                seq\n",
       "8         2  [699, 1826, 2277, 1934, 982, 538, 2415, 2530, ...\n",
       "9         3  [1120, 1025, 3235, 3294, 466, 253, 1106, 1108,...\n",
       "17        4  [2078, 1575, 188, 1546, 2864, 1741, 2520, 3042...\n",
       "20        5  [1767, 3360, 3370, 1837, 373, 259, 358, 2859, ...\n",
       "46        9  [1915, 713, 1160, 1148, 958, 970, 1142, 3120, ...\n",
       "...     ...                                                ...\n",
       "39457  6030  [858, 1178, 346, 2511, 2599, 3216, 1414, 1205,...\n",
       "39464  6033  [906, 1247, 2914, 513, 334, 852, 2521, 1485, 1...\n",
       "39519  6037  [859, 3165, 1120, 1965, 346, 1288, 1007, 1066,...\n",
       "39524  6038  [843, 1192, 852, 1014, 1784, 2024, 889, 2026, ...\n",
       "39538  6039  [1887, 1767, 1121, 2374, 1236, 892, 2520, 1536...\n",
       "\n",
       "[2978 rows x 2 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find a user with a sequence length < 25\n",
    "train_df[train_df['seq'].apply(len) < 25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'val': val,\n",
    "    'test': test,\n",
    "    'umap': umap,\n",
    "    'smap': smap\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train as pickle\n",
    "train_df.to_pickle(\"data/lstr/train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '{}_min_rating{}-min_uc{}-min_sc{}-split{}_except_train' \\\n",
    "            .format('ml-1m', 0, 5, 0, 'leave_one_out')\n",
    "\n",
    "with open('data/lstr/{}.pkl'.format(folder_name), 'wb') as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get negative train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "dataset_folder = Path('data/')\n",
    "dataset_filename = '{}_min_rating{}-min_uc{}-min_sc{}-split{}'.format('ml-1m', 3, 5, 0, 'leave_one_out')\n",
    "dataset_file = dataset_folder.joinpath(dataset_filename + '.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: dict[str, dict[str, list[int]]] = pickle.load(open(dataset_file, 'rb'))\n",
    "train_df: pd.DataFrame = pd.read_pickle(dataset_folder.joinpath('lstr/train.pkl'))\n",
    "val = dataset['val']\n",
    "test = dataset['test']\n",
    "umap = dataset['umap']\n",
    "smap = dataset['smap']\n",
    "user_count = len(umap)\n",
    "item_count = len(smap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "\n",
    "def generate_negative_samples(seed: int, sample_size: int = 100) -> dict[str, list[int]]:\n",
    "    np.random.seed(seed)\n",
    "    negative_samples = {}\n",
    "    for user in trange(user_count):\n",
    "        if isinstance(train[user][1], tuple):\n",
    "            seen = set([x[0] for x in train[user]])\n",
    "            seen.update([x[0] for x in val[user]])\n",
    "            seen.update(x[0] for x in test[user])\n",
    "        else:\n",
    "            seen = set(train[user])\n",
    "            seen.update(val[user])\n",
    "            seen.update(test[user])\n",
    "        \n",
    "        samples = []\n",
    "        for _ in range(sample_size):\n",
    "            item = np.random.choice(item_count) + 1\n",
    "            while item in seen or item in samples:\n",
    "                item = np.random.choice(item_count) + 1\n",
    "            samples.append(item)\n",
    "        \n",
    "        negative_samples[user] = samples\n",
    "    \n",
    "    return negative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6040/6040 [00:00<00:00, 177649.97it/s]\n",
      "100%|██████████| 6040/6040 [00:06<00:00, 908.41it/s] \n"
     ]
    }
   ],
   "source": [
    "negative_train_samples = generate_negative_samples(0, 0)\n",
    "negative_test_samples = generate_negative_samples(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Negative train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_train_save_file_path = '{}-sample_size{}-seed{}-{}.pkl'.format('random', 100, 42, 'train')\n",
    "negative_train_save_file = dataset_folder.joinpath(negative_train_save_file_path)\n",
    "with negative_train_save_file.open('wb') as f:\n",
    "    pickle.dump(negative_train_samples, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "import torch.backends.cudnn as cudnn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTrainDataset(data_utils.Dataset):\n",
    "    def __init__(self, max_len: int, mask_prob: float, mask_token: int, num_items: int, rng: random.Random, long_len: int):\n",
    "        # self.users = sorted(self.u2seq.keys())\n",
    "        self.max_len = max_len\n",
    "        self.train_df = pd.read_pickle('data/lstr/train.pkl')\n",
    "        self.mask_prob = mask_prob\n",
    "        self.mask_token = mask_token\n",
    "        self.num_items = num_items\n",
    "        self.rng = rng\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_df)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        seq = self.train_df.seq[index]\n",
    "\n",
    "        tokens: list[int] = []\n",
    "        labels: list[int] = []\n",
    "        for s in seq:\n",
    "            prob = self.rng.random()\n",
    "            if prob < self.mask_prob:\n",
    "                prob /= self.mask_prob\n",
    "\n",
    "                if prob < 0.8:\n",
    "                    tokens.append(self.mask_token)\n",
    "                elif prob < 0.9:\n",
    "                    tokens.append(self.rng.randint(1, self.num_items))\n",
    "                else:\n",
    "                    tokens.append(s)\n",
    "\n",
    "                labels.append(s)\n",
    "            else:\n",
    "                tokens.append(s)\n",
    "                labels.append(0)\n",
    "\n",
    "        # May not need this since the sequences are already cut.\n",
    "        # tokens = tokens[-self.max_len:]\n",
    "        # labels = labels[-self.max_len:]\n",
    "\n",
    "        mask_len = self.max_len - len(tokens)\n",
    "\n",
    "        tokens = [0] * mask_len + tokens\n",
    "        labels = [0] * mask_len + labels\n",
    "\n",
    "        # Split the sequences into two parts.\n",
    "        # Long and short sequence.\n",
    "        long_tokens = tokens[:self.long_len]\n",
    "        long_labels = labels[:self.long_len]\n",
    "\n",
    "        short_tokens = tokens[self.long_len:]\n",
    "        short_labels = labels[self.long_len:]\n",
    "\n",
    "        return torch.LongTensor(long_tokens), torch.LongTensor(long_labels), torch.LongTensor(short_tokens), torch.LongTensor(short_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = BertTrainDataset(train_df, 25, 0.15, item_count+1, item_count, random.Random(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Dataset (Val and Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEvalDataset(data_utils.Dataset):\n",
    "    def __init__(self, u2seq: dict[str, list[int]], u2answer: dict[str, list[int]], max_len: int, mask_token: int, negative_samples: dict[str, list[int]]) -> None:\n",
    "        self.u2seq = u2seq\n",
    "        self.users = sorted(self.u2seq.keys())\n",
    "        self.u2answer = u2answer\n",
    "        self.max_len = max_len\n",
    "        self.mask_token = mask_token\n",
    "        self.negative_samples = negative_samples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[torch.LongTensor, torch.LongTensor, torch.LongTensor]:\n",
    "        user = self.users[index]\n",
    "        seq = self.u2seq[user]\n",
    "        answer = self.u2answer[user]\n",
    "        negs = self.negative_samples[user]\n",
    "\n",
    "        candidates = answer + negs\n",
    "        labels = [1] * len(answer) + [0] * len(negs)\n",
    "\n",
    "        seq = seq + [self.mask_token]\n",
    "        seq = seq[-self.max_len:]\n",
    "        padding_len = self.max_len - len(seq)\n",
    "        seq = [0] * padding_len + seq\n",
    "\n",
    "        return torch.LongTensor(seq), torch.LongTensor(candidates), torch.LongTensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random_seed_as(random_seed: int) -> None:\n",
    "    random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(pl.LightningModule):\n",
    "    def __init__(self, max_len: int, d_model: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        self.pe = nn.Embedding(max_len, d_model)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = x.size(0)\n",
    "        return self.pe.weight.unsqueeze(0).repeat(batch_size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEmbedding(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    BERT Embedding which is consisted with under features\n",
    "        1. TokenEmbedding : normal embedding matrix\n",
    "        2. PositionalEmbedding : adding positional information using sin, cos\n",
    "        2. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2)\n",
    "        sum of all these features are output of BERTEmbedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size: int, embed_size: int, max_len: int, dropout: float = 0.1) -> None:\n",
    "        \"\"\"\n",
    "        :param vocab_size: total vocab size\n",
    "        :param embed_size: embedding size of token embedding\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.token = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_size)\n",
    "        self.position = PositionalEmbedding(max_len=max_len, d_model=embed_size)\n",
    "        # self.segment = SegmentEmbedding(embed_size=self.token.embedding_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "    def forward(self, sequence: torch.Tensor) -> torch.Tensor:\n",
    "        x: torch.Tensor = self.token(sequence) + self.position(sequence)  # + self.segment(segment_label)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_template(args):\n",
    "    if args.template is None:\n",
    "        return\n",
    "\n",
    "    elif args.template.startswith('train_bert'):\n",
    "        args.mode = 'train'\n",
    "\n",
    "        args.dataset_code = 'ml-' + input('Input 1 for ml-1m, 20 for ml-20m: ') + 'm'\n",
    "        args.min_rating = 0 if args.dataset_code == 'ml-1m' else 4\n",
    "        args.min_uc = 5\n",
    "        args.min_sc = 0\n",
    "        args.split = 'leave_one_out'\n",
    "\n",
    "        args.dataloader_code = 'bert'\n",
    "        batch = 64\n",
    "        args.train_batch_size = batch\n",
    "        args.val_batch_size = batch\n",
    "        args.test_batch_size = batch\n",
    "\n",
    "        args.train_negative_sampler_code = 'random'\n",
    "        args.train_negative_sample_size = 0\n",
    "        args.train_negative_sampling_seed = 0\n",
    "        args.test_negative_sampler_code = 'random'\n",
    "        args.test_negative_sample_size = 100\n",
    "        args.test_negative_sampling_seed = 98765\n",
    "\n",
    "        args.trainer_code = 'bert'\n",
    "        args.device = 'cuda'\n",
    "        args.num_gpu = 1\n",
    "        args.device_idx = '0'\n",
    "        args.optimizer = 'Adam'\n",
    "        args.lr = 0.001\n",
    "        args.enable_lr_schedule = True\n",
    "        args.decay_step = 25\n",
    "        args.gamma = 1.0\n",
    "        args.num_epochs = 100 if args.dataset_code == 'ml-1m' else 200\n",
    "        args.metric_ks = [1, 5, 10, 20]\n",
    "        args.best_metric = 'NDCG@10'\n",
    "\n",
    "        args.model_code = 'bert'\n",
    "        args.model_init_seed = 0\n",
    "\n",
    "        args.bert_dropout = 0.1\n",
    "        args.bert_hidden_units = 256\n",
    "        args.bert_mask_prob = 0.15\n",
    "        args.bert_max_len = 100\n",
    "        args.bert_num_blocks = 2\n",
    "        args.bert_num_heads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import NumberType\n",
    "\n",
    "\n",
    "def recalls_and_ndcgs_for_ks(scores: torch.Tensor, labels: torch.Tensor, ks: list[int]):\n",
    "    metrics: dict[str, NumberType] = {}\n",
    "\n",
    "    # Why is this being done?\n",
    "    # scores = scores\n",
    "    # labels = labels\n",
    "    answer_count = labels.sum(1)\n",
    "\n",
    "    labels_float = labels.float()\n",
    "    rank = (-scores).argsort(dim=1)\n",
    "    cut = rank\n",
    "    for k in sorted(ks, reverse=True):\n",
    "        cut = cut[:, :k]\n",
    "        hits = labels_float.gather(1, cut)\n",
    "        \"\"\"\n",
    "            Recall at k is the proportion of relevant items found in the top-k recommendations.\n",
    "            Recall@k = (# of recommended items @k that are relevant) / (total # of relevant items)\n",
    "        \"\"\"\n",
    "        numerator = hits.sum(1)\n",
    "        denominator = torch.min(torch.Tensor([k]).to(labels.device), labels.sum(1).float())\n",
    "        metrics['Recall@%d' % k] = \\\n",
    "            (numerator / denominator).mean().cpu().item()\n",
    "\n",
    "        \"\"\"\n",
    "            NDCG at k is the average of the normalized DCG scores of the top-k recommendations.\n",
    "            NDCG@k = DCG@k / IDCG@k\n",
    "            DCG@K = SUM( recc_i / log2(i + 1))\n",
    "            IDCG@K = SUM( real_i / log2(i + 1))\n",
    "        \"\"\"\n",
    "        position = torch.arange(2, 2+k)\n",
    "        weights = 1 / torch.log2(position.float())\n",
    "        # Discounted cumulative gain at k\n",
    "        dcg = (hits * weights.to(hits.device)).sum(1)\n",
    "        # Ideal discounted cumulative gain at k\n",
    "        # idcg = (labels_float * weights.to(labels_float.device)).sum(1)\n",
    "        idcg = torch.Tensor([weights[:min(int(n), k)].sum()\n",
    "                            for n in answer_count]).to(dcg.device)\n",
    "        # What is the above code doing\n",
    "        ndcg = (dcg / idcg).mean()\n",
    "        metrics['NDCG@%d' % k] = ndcg.cpu().item()\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(pl.LightningModule):\n",
    "    def __init__(self, args: dotdict):\n",
    "        super().__init__()\n",
    "\n",
    "        fix_random_seed_as(args.model_init_seed)\n",
    "        # self.init_weights()\n",
    "\n",
    "        self.args = args\n",
    "        long_len: int = args.bert_long_len\n",
    "        short_len: int = args.bert_short_len\n",
    "        num_items: int = args.num_items\n",
    "        n_layers: int = args.bert_num_blocks\n",
    "        self.heads: int = args.bert_num_heads\n",
    "        vocab_size: int = num_items + 2\n",
    "        hidden: int = args.bert_hidden_units\n",
    "        self.hidden = hidden\n",
    "        self.metric_ks = args.metric_ks\n",
    "        dropout: float = args.bert_dropout\n",
    "        self.ce = nn.CrossEntropyLoss(ignore_index=0)\n",
    "        # embedding for BERT, sum of positional, segment, token embeddings\n",
    "        self.long_embedding = BERTEmbedding(\n",
    "            vocab_size=vocab_size, embed_size=self.hidden, max_len=long_len, dropout=dropout)\n",
    "        self.short_embedding = BERTEmbedding(\n",
    "            vocab_size=vocab_size, embed_size=self.hidden, max_len=short_len, dropout=dropout)\n",
    "        # multi-layers transformer blocks, deep network\n",
    "        self.encoder = nn.TransformerEncoderLayer(hidden, self.heads, hidden * 4, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(self.encoder, n_layers)\n",
    "        self.out = nn.Linear(self.hidden, num_items + 1)\n",
    "\n",
    "    def forward(self, long_seq: torch.Tensor, short_seq: torch.Tensor) -> torch.Tensor:\n",
    "        long_mask = (long_seq == 0).unsqueeze(1).repeat(self.heads, long_seq.size(1), 1)\n",
    "        long_seq = self.long_embedding(long_seq)\n",
    "        long_output: torch.Tensor = self.transformer(long_seq, long_mask)\n",
    "\n",
    "        short_mask = (short_seq == 0).unsqueeze(1).repeat(self.heads, short_seq.size(1), 1)\n",
    "        short_seq = self.short_embedding(short_seq)\n",
    "        short_output: torch.Tensor = self.transformer(short_seq, short_mask)\n",
    "\n",
    "        output = torch.cat([long_output, short_output], dim=1)\n",
    "\n",
    "        # output = output.masked_fill(torch.isnan(output), 0)\n",
    "        return self.out(output)\n",
    "\n",
    "    def init_weights(self):\n",
    "        pass\n",
    "\n",
    "    def training_step(self, batch: tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        batch_size = batch[0].size(0)\n",
    "        long_seq, long_labels, short_seq, short_labels = batch\n",
    "        logits: torch.Tensor = self(long_seq, short_seq)\n",
    "\n",
    "        logits = logits.view(-1, logits.size(-1))\n",
    "        labels = labels.view(-1)\n",
    "        loss: torch.Tensor = self.ce(logits, labels)\n",
    "        # log_data = {\n",
    "        #     'state_dict': (self._create_state_dict()),\n",
    "        #     \"train/ce\": loss.item()\n",
    "        # }\n",
    "        self.log(\n",
    "            \"train/ce\", loss, on_step=True, on_epoch=False, prog_bar=True\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: tuple[torch.Tensor, torch.Tensor, torch.Tensor], batch_idx: int) -> dict[str, NumberType]:\n",
    "        seq, candidates, labels = batch\n",
    "        scores: torch.Tensor = self(seq)\n",
    "        scores = scores[:, -1, :]\n",
    "        scores = scores.gather(1, candidates)\n",
    "        metrics = recalls_and_ndcgs_for_ks(scores, labels, self.metric_ks)\n",
    "\n",
    "        self.log_dict(metrics, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch: tuple[torch.Tensor, torch.Tensor, torch.Tensor], batch_idx: int) -> dict[str, NumberType]:\n",
    "        seq, candidates, labels = batch\n",
    "        scores: torch.Tensor = self(seq)\n",
    "        scores = scores[:, -1, :]\n",
    "        scores = scores.gather(1, candidates)\n",
    "        metrics = recalls_and_ndcgs_for_ks(scores, labels, self.metric_ks)\n",
    "\n",
    "        self.log_dict(metrics, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        return metrics\n",
    "\n",
    "    def validation_epoch_end(self, outputs: list[dict[str, NumberType]]) -> None:\n",
    "        # outputs is a list of dicts\n",
    "        avg_metrics = {}\n",
    "        for metric in outputs[0].keys():\n",
    "            avg_metrics[metric] = torch.mean(torch.FloatTensor([x[metric] for x in outputs]))\n",
    "        \n",
    "        self.log_dict(avg_metrics, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "\n",
    "\n",
    "        # for metric in outputs[0].keys():\n",
    "        #     self.log(metric, torch.mean(torch.stack(\n",
    "        #         [output[metric] for output in outputs])), on_step=False, on_epoch=True, prog_bar=False)\n",
    "    \n",
    "    def test_epoch_end(self, outputs: list[dict[str, NumberType]]) -> None:\n",
    "        # outputs is a list of dicts\n",
    "        metric_names = outputs[0].keys()\n",
    "        avg_metrics = dict.fromkeys(metric_names, [])\n",
    "        for output in outputs:\n",
    "            for metric_name in metric_names:\n",
    "                avg_metrics[metric_name].append(output[metric_name])\n",
    "        \n",
    "        for metric_name in metric_names:\n",
    "            avg_metrics[metric_name] = torch.mean(torch.stack(avg_metrics[metric_name]))\n",
    "        \n",
    "        self.log_dict(avg_metrics, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        # for metric in outputs[0].keys():\n",
    "        #     self.log(metric, torch.mean(torch.stack(\n",
    "        #         [output[metric] for output in outputs])), on_step=False, on_epoch=True, prog_bar=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        if self.args['optimizer'].lower() == 'adam':\n",
    "            return torch.optim.Adam(self.parameters(), lr=self.args['lr'], weight_decay=self.args['weight_decay'])\n",
    "        elif self.args['optimizer'].lower() == 'sgd':\n",
    "            return torch.optim.SGD(self.parameters(), lr=self.args['lr'], weight_decay=self.args['weight_decay'], momentum=self.args['momentum'])\n",
    "        else:\n",
    "            raise ValueError('Optimizer not supported')\n",
    "\n",
    "    def _create_state_dict(self):\n",
    "        return {\n",
    "            'model_state_dict': self.model.module.state_dict() if self.is_parallel else self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "        }\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = BertTrainDataset(100, 0.15, item_count+1, item_count, random.Random(0), 20)\n",
    "        self.val_dataset = BertEvalDataset(train, val, 100, item_count+1, negative_test_samples)\n",
    "        self.test_dataset = BertEvalDataset(train, test, 100, item_count+1, negative_test_samples)\n",
    "\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return data_utils.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=128,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return data_utils.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=128,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return data_utils.DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=128,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'bert_max_len': 100,\n",
    "    'bert_long_len': 20,\n",
    "    'bert_short_len': 5,\n",
    "    'num_items': item_count,\n",
    "    'bert_num_blocks': 2,\n",
    "    'bert_num_heads': 4,\n",
    "    'bert_hidden_units': 256,\n",
    "    'bert_dropout': 0.1,\n",
    "    'model_init_seed': 42,\n",
    "    'bert_mask_prob': 0.15,\n",
    "    'metric_ks': [1, 5, 10, 20],\n",
    "    'lr': 0.001,\n",
    "    'weight_decay': 0.0,\n",
    "    'optimizer': 'Adam',\n",
    "}\n",
    "\n",
    "args = dotdict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                    | Params\n",
      "------------------------------------------------------------\n",
      "0 | ce              | CrossEntropyLoss        | 0     \n",
      "1 | long_embedding  | BERTEmbedding           | 954 K \n",
      "2 | short_embedding | BERTEmbedding           | 950 K \n",
      "3 | encoder         | TransformerEncoderLayer | 789 K \n",
      "4 | transformer     | TransformerEncoder      | 1.6 M \n",
      "5 | out             | Linear                  | 952 K \n",
      "------------------------------------------------------------\n",
      "5.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.2 M     Total params\n",
      "20.907    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'short_seq'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [138], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m BERT(args)\n\u001b[0;32m      2\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m, devices\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, max_epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model)\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:696\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[39mRuns the full optimization routine.\u001b[39;00m\n\u001b[0;32m    679\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[39m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[1;32m--> 696\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    697\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    698\u001b[0m )\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[1;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    649\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    651\u001b[0m \u001b[39m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m \u001b[39mas\u001b[39;00m exception:\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:735\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    731\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m    732\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_ckpt_path(\n\u001b[0;32m    733\u001b[0m     ckpt_path, model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    734\u001b[0m )\n\u001b[1;32m--> 735\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[0;32m    737\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    738\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1166\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[0;32m   1164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[1;32m-> 1166\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m   1168\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1169\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1252\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[0;32m   1251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[1;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1274\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_training_routine()\n\u001b[0;32m   1273\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[0;32m   1276\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[0;32m   1277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1343\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[0;32m   1342\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m-> 1343\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m   1345\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1347\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\loops\\dataloader\\evaluation_loop.py:155\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    154\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[1;32m--> 155\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[0;32m    157\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py:200\u001b[0m, in \u001b[0;36mLoop.run\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[0;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:143\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[1;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[0;32m    142\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n\u001b[0;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\evaluation_epoch_loop.py:240\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \n\u001b[0;32m    231\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m    the outputs of the step\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 240\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(hook_name, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[0;32m    242\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1704\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1701\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1704\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1706\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m   1707\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:370\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[0;32m    369\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[1;32m--> 370\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mvalidation_step(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn [136], line 66\u001b[0m, in \u001b[0;36mBERT.validation_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidation_step\u001b[39m(\u001b[39mself\u001b[39m, batch: \u001b[39mtuple\u001b[39m[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor], batch_idx: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, NumberType]:\n\u001b[0;32m     65\u001b[0m     seq, candidates, labels \u001b[39m=\u001b[39m batch\n\u001b[1;32m---> 66\u001b[0m     scores: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(seq)\n\u001b[0;32m     67\u001b[0m     scores \u001b[39m=\u001b[39m scores[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[0;32m     68\u001b[0m     scores \u001b[39m=\u001b[39m scores\u001b[39m.\u001b[39mgather(\u001b[39m1\u001b[39m, candidates)\n",
      "File \u001b[1;32me:\\Coding\\bst-lstr\\bst\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'short_seq'"
     ]
    }
   ],
   "source": [
    "model = BERT(args)\n",
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=1, max_epochs=100)\n",
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 ('bst': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ca0676aa18c95b2f4ddbcd7227ae51f1b24dbd48c44e8096aadec2eff2cfaf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
